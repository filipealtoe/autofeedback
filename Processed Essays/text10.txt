The GDPR is a newly effective regulation in European Union law with the stated aim of protecting all EU citizens from privacy and data breaches in today's data-driven world. To that end, the new regulation contains numerous rules on the use of personal data collected from users. One section note will be quoted at length, for its contents will be extensively used in the following response. From the declarations at the beginning of the GDPR, section 39:

Any processing of personal data should be lawful and fair. It should be transparent to natural persons that personal data concerning them are collected, used, consulted or otherwise processed and to what extent the personal data are or will be processed. The principle of transparency requires that any information and communication relating to the processing of those personal data be easily accessible and easy to understand, and that clear and plain language be used.

Natural persons should be made aware of risks, rules, safeguards and rights in relation to the processing of personal data and how to exercise their rights in relation to such processing. In particular, the specific purposes for which personal data are processed should be explicit and legitimate and determined at the time of the collection of the personal data. The personal data should be adequate, relevant and limited to what is necessary for the purposes for which they are processed. This requires, in particular, ensuring that the period for which the personal data are stored is limited to a strict minimum.

With respect to our prompt, which asks for the regulations mandates on the topic of using personal data for individualization of personal user experiences, this section is extremely pertinent. To summarize, there are several important points contained in the declaration above. First, it says right off the bat that it should be transparent to users what data is collected about them, how it is used, and how it is processed. Second, that this information is easily accessible to the user and is written in clear and plain language. Third, it says that users should be explicitly told the purposes for which their data is being collected. Finally, it says that the regulation will ensure that the data is kept for as short a time as possible.

Overall, these rules have a profound impact on the use of AI in the creation of personalized experiences. First, the direction that users should be able to know how their data is processed could be very problematic in areas such as machine learning, where artifacts such as deep neural networks are popular and understanding why a network returned a given result is often difficult even for experts.

This point is only compounded by the following point that it must be explained in plain and clear language as mentioned, even experts have difficulty with the interpretability problem. To that point, a recent paper written by researchers at Google, describes different ways that interpretability interfaces could be designed to communicate this information to laypeople, but to describe current methods as clear and plain would dramatically incorrect.
Moreover, the rules stating that users must be told how their data will be used at the time of collection is problematic from an R&D perspective, since in many cases user data is used to optimize or curate user experiences in ways that are not immediately foreseeable when designing data collection systems.