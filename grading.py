'''
Created on Mar 4, 2019

@author: filipe
'''

import os, sys
from glob import glob
from summary import summary
import re, ntpath
from similarity import similarity
from conceptmap import conceptmap
from shutil import copyfile
from nltk.tokenize import sent_tokenize


def get_highest_similarity(focus_sentence, sentences, similarity_threshold):
    most_similar_sentence = ''
    highest_score = 0
    for sentence in sentences:
        score = similarity.symmetric_sentence_similarity(focus_sentence, sentence)
        if ((score >= similarity_threshold) and (score > highest_score)):
            most_similar_sentence = sentence
            highest_score = score
    return most_similar_sentence, highest_score

if __name__ == '__main__':

    plotGraph = False  #For debugging purposes
    essayDir = "grading/essays"
    jsonDir = "grading/jsonessays"
    summaryDir = "grading/summaries"
    rubricDir = "grading/rubric"
    path = os.path.dirname(sys.argv[0])
    essay_path = os.path.join(path, essayDir)
    json_path = os.path.join(path, jsonDir)
    summary_path = os.path.join(path, summaryDir)
    rubric_path = os.path.join(path, rubricDir)
    summaryfiles = []
    
    ### TUNNING PARAMETERS
    wordlimit = 200
    phraselimit = 10
    similarity_thereshold = 0.4
    
    #Delete left over processed files
    name = glob(json_path + "/*.json")
    for fname in enumerate(name):
        try:
            os.remove(fname[1])
        except OSError:
            pass
    
    #Repeat process for all essay files
    name = glob(essay_path + "/*.txt")
    WORD = re.compile(r'[\w\.]+')
    for fname in enumerate(name):   
        with open(fname[1], 'r') as g:
            text = g.read()
        #text = open(fname[1], 'r').read()
        text = " ".join(WORD.findall(text)) 
        filename = ntpath.basename(fname[1]).split(".")[0] + "_o2.json"
        path_stage1 = fname[1].split('.txt')[0] + '_o1.json'
        summary.generateGraph(text, filename, json_path, plotGraph=False)
        
        #Generate summary    
        path_stage2 = os.path.join(json_path, filename)
        path_stage3 = path_stage2.replace('o2', 'o3')
        path_stage1 = path_stage2.replace('o2', 'o1')
        summarytext, keyconcepts = summary.summarize(path_stage1, path_stage2, path_stage3, wordlimit=wordlimit, phraselimit=phraselimit)
        filename = ntpath.basename(fname[1]).split(".")[0] + '_summary.txt'
        summarypath = os.path.join(summaryDir, filename)
        with open(summarypath, 'w') as f:
            f.write(summarytext)
        summaryfiles.append(os.path.join(path, summarypath))
        #Generate summary concept map
        filename = ntpath.basename(fname[1]).split(".")[0] + "_o2.json"
        summary.generateGraph(summarytext, filename, summary_path, plotGraph=False)

    #Copy rubric files to summaries directory so it can be compared with test essay
    rubric_files = name = glob(rubric_path + "/*.*")
    for rubric_file in rubric_files:
        rubric_filename = ntpath.basename(rubric_file)
        dest_rubric_filename = os.path.join(summary_path, rubric_filename)
        copyfile(rubric_file, dest_rubric_filename)
    
    #Similarities between all rubric and test essay
    rubric_text_file = os.path.join(summary_path, 'rubric.txt')
    summaryfiles.append(rubric_text_file)
    resultText, similarityvalue = similarity.summaries_multiplefiles_similarity(summaryfiles)
    resultFile = os.path.join(rubric_path, 'autogeneratedrubric.csv')
    with open(resultFile, 'w') as f:
            f.write(resultText)
    print ('Analysis complete...')
    print 
    print ('Similarity Score Between Rubric and Test Essay: ' + str(similarityvalue[0]['similarity']))
    
    #Compare each sentence of student's essay to each sentence on rubric
    with open(rubric_text_file, 'r') as f:
            rubric_text = f.read()
    student_sentences = sent_tokenize(summarytext)
    rubric_sentences = sent_tokenize(rubric_text)
    diff_rubric_sentences = rubric_sentences.copy()
    number_not_found_sentences = 0
    good_concepts = []
    for sentence in student_sentences:
        rubric_similar_sentence, score = get_highest_similarity(sentence, rubric_sentences, similarity_thereshold)
        try:
            diff_rubric_sentences.remove(rubric_similar_sentence)
            good_concepts.append(rubric_similar_sentence)
        except:
            number_not_found_sentences += 1    
    #Flattens each array back to string so it can be passed through concept map generation
    good_concepts = ''.join(good_concepts)
    diff_rubric_sentences = ''.join(diff_rubric_sentences)
    conceptmap.generate_conceptmap(good_concepts, rubric_path, plotConceptMap=True, mapfile= 'good_concepts.gv')
    conceptmap.generate_conceptmap(diff_rubric_sentences, rubric_path, plotConceptMap=True, mapfile = 'missing_concepts.gv')
    print ('Total Number of Missing Concepts: ' + str(number_not_found_sentences))
